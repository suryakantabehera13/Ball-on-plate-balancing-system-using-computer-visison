# -*- coding: utf-8 -*-
"""BnP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TrGid2XwIIRY2szTf_8N9v1vOgH94Mn5
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Load the video
video_path = '/content/drive/MyDrive/BNP/Take-1.mp4'
cap = cv2.VideoCapture(video_path)

# Get the actual frame size
ret, frame = cap.read()
if not ret:
    print("Error: Couldn't read the video file.")
    cap.release()
    exit()

frame_height, frame_width = frame.shape[:2]

# Define the codec and create VideoWriter object using actual frame size
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter('output_ball_1new.avi', fourcc, 20.0, (frame_width, frame_height))

# Initialize a list to store the ball's path (x, y coordinates)
ball_path = []

# Background subtractor for foreground detection (better than simple color threshold)
fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)

# Kernel for morphological operations to clean up noise
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
frame_count = 0
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Apply background subtraction to isolate the moving object (ball)
    fgmask = fgbg.apply(frame)

    # Apply morphological operations to remove noise
    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)
    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel)

    # Find contours in the mask
    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Only proceed if contours are found
    if len(contours) > 0:
        # Find the largest contour by area (likely the ball)
        largest_contour = max(contours, key=cv2.contourArea)

        # Calculate the bounding box of the largest contour
        x, y, w, h = cv2.boundingRect(largest_contour)

        # Filter out too small contours (noise)
        if w * h > 500:  # Adjust this threshold based on ball size
            # Draw a rectangle around the ball
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

            # Draw the center of the ball
            center_x, center_y = x + w // 2, y + h // 2
            cv2.circle(frame, (center_x, center_y), 5, (0, 0, 255), -1)

            # Save the ball's coordinates
            ball_path.append((center_x, center_y))

            # Draw the path of the ball
            for i in range(1, len(ball_path)):
                if ball_path[i - 1] is None or ball_path[i] is None:
                    continue
                cv2.line(frame, ball_path[i - 1], ball_path[i], (0, 0, 255), 2)

    # Write the frame to the output video
    out.write(frame)

    # Show the frame with ball detection
    cv2_imshow(frame)

    # Break the loop if 'q' is pressed
    frame_count += 1
    if frame_count >= 100:
        break

# Release video capture and writer objects
cap.release()
out.release()
cv2_imshow(np.zeros((1,1,3), dtype=np.uint8))

# Save the path coordinates to a text file
with open('ball_path_data1new.txt', 'w') as f:
    for coord in ball_path:
        f.write(f"{coord}\n")

import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow  # Import cv2_imshow

# Global lists to store selected points
src_points = []
dst_points = []

def select_points(event, x, y, flags, param):
    # Left-click to select a point
    if event == cv2.EVENT_LBUTTONDOWN:
        param.append((x, y))

def collect_points(image_path, point_list, window_name):
    # Load and display the image
    image = cv2.imread(image_path)
    cv2_imshow(image)

    # Set the mouse callback to collect points
    cv2.setMouseCallback(window_name, select_points, point_list)
    print(f"Select points on {window_name} window. Press 'q' when done.")

    # Wait for the user to finish selecting points
    while True:
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):  # Quit on pressing 'q'
            break

    cv2.destroyAllWindows()
    return np.array(point_list, dtype=np.float32)

def compute_homography_and_transform(src_points, dst_points):
    # Compute homography matrix
    H, _ = cv2.findHomography(src_points, dst_points, cv2.RANSAC)
    print("\nComputed Homography Matrix:\n", H)

    # Transform the source points using the homography matrix
    transformed_points = cv2.perspectiveTransform(src_points.reshape(-1, 1, 2), H).reshape(-1, 2)
    return H, transformed_points

def plot_images_with_points(img1_path, img2_path, src_points, dst_points, mapped_points):
    img1 = cv2.cvtColor(cv2.imread(img1_path), cv2.COLOR_BGR2RGB)
    img2 = cv2.cvtColor(cv2.imread(img2_path), cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(15, 8))

    # Plot source image with selected points
    plt.subplot(1, 2, 1)
    plt.imshow(img1)
    plt.scatter(src_points[:, 0], src_points[:, 1], color='red', label='Source Points')
    plt.title("Source Image")
    plt.axis("off")

    # Plot destination image with mapped points
    plt.subplot(1, 2, 2)
    plt.imshow(img2)
    plt.scatter(dst_points[:, 0], dst_points[:, 1], color='green', label='Destination Points')
    plt.scatter(mapped_points[:, 0], mapped_points[:, 1], color='yellow', marker='x', label='Mapped Points')
    plt.title("Destination Image")
    plt.axis("off")

    # Draw lines connecting points
    for i in range(len(src_points)):
        plt.plot(
            [src_points[i, 0], mapped_points[i, 0]],
            [src_points[i, 1], mapped_points[i, 1]],
            'y--'
        )

    plt.legend()
    plt.show()

# Main pipeline
def main_pipeline(img1_path, img2_path):
    # Collect corresponding points from both images
    src_points = np.array([[100, 100], [200, 100], [200, 200], [100, 200]], dtype=np.float32) # example points
    dst_points = np.array([[120, 120], [220, 120], [220, 220], [120, 220]], dtype=np.float32) # example points

    # Compute homography and transform points
    H, mapped_points = compute_homography_and_transform(src_points, dst_points)

    # Plot results
    plot_images_with_points(img1_path, img2_path, src_points, dst_points, mapped_points)




img1_path = '/content/drive/MyDrive/BNP/img1 ball.jpeg'  # Replace with the actual path to source image
img2_path = '/content/drive/MyDrive/BNP/img2 ball.jpeg'  # Replace with the actual path to destination image

# Run the pipeline
main_pipeline(img1_path, img2_path)

import cv2
import numpy as np
from google.colab.patches import cv2_imshow  # Import for displaying images in Colab

def main():
    # Load the two images
    img1 = cv2.imread('/content/drive/MyDrive/BNP/img1 ball.jpeg')
    img2 = cv2.imread('/content/drive/MyDrive/BNP/img2 ball.jpeg')

    # Convert images to grayscale
    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

    # Detect ORB keypoints and descriptors
    orb = cv2.ORB_create()
    kp1, des1 = orb.detectAndCompute(gray1, None)
    kp2, des2 = orb.detectAndCompute(gray2, None)

    # Match descriptors using BFMatcher
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(des1, des2)

    # Sort matches by distance
    matches = sorted(matches, key=lambda x: x.distance)

    # Extract location of good matches
    pts1 = np.zeros((len(matches), 2), dtype='float32')
    pts2 = np.zeros((len(matches), 2), dtype='float32')

    for i, match in enumerate(matches):
        pts1[i, :] = kp1[match.queryIdx].pt
        pts2[i, :] = kp2[match.trainIdx].pt

    # Compute Homography
    H, status = cv2.findHomography(pts1, pts2)

    # Map points from img1 to img2 using Homography
    mapped_points = cv2.perspectiveTransform(pts1.reshape(-1, 1, 2), H)

    # Display results
    for i in range(len(mapped_points)):
        print(f'Original Point in Image 1: {pts1[i]} -> Mapped Point in Image 2: {mapped_points[i][0]}')

        # Draw the lines between matched points
        pt1 = tuple(pts1[i].astype(int))
        pt2 = tuple(mapped_points[i][0].astype(int))
        cv2.line(img1, pt1, pt2, (0, 255, 0), 1)

    # Show images with lines drawn using cv2_imshow
    cv2_imshow(img1)  # Use cv2_imshow instead of cv2.imshow
    cv2_imshow(img2)  # Use cv2_imshow instead of cv2.imshow

    # Remove or replace cv2.waitKey(0) and cv2.destroyAllWindows()
    # as they are not needed in Colab with cv2_imshow
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()

if __name__ == "__main__":
    main()



import matplotlib.pyplot as plt

try:
    ball_path = []
    with open('ball_path_data1new.txt', 'r') as f:
        for line in f:
            x, y = map(int, line[1:-2].split(', ')) # Extract x, y and handle string format
            ball_path.append((x,y))
except FileNotFoundError:
    print("ball_path_data1new.txt not found. Please run the ball tracking code first.")
    ball_path = []


if ball_path:
    x_coords, y_coords = zip(*ball_path)
    plt.figure(figsize=(10, 6))
    plt.plot(x_coords, y_coords, marker='o', linestyle='-')
    plt.xlabel("X Coordinate (pixels)")
    plt.ylabel("Y Coordinate (pixels)")
    plt.title("Ball Path")
    plt.grid(True)
    plt.show()

try:
    ball_path = []
    with open('ball_path_data1new.txt', 'r') as f:
        for line in f:
            x, y = map(int, line[1:-2].split(', ')) # Extract x, y and handle string format
            ball_path.append((x,y))
except FileNotFoundError:
    print("ball_path_data1new.txt not found. Please run the ball tracking code first.")
    ball_path = []

if ball_path:
    # Extract x and y coordinates
    x_coords, y_coords = zip(*ball_path)

    # Calculate time for each frame (assuming constant frame rate)
    frame_rate = 20  # Replace with actual frame rate if known
    time = [i / frame_rate for i in range(len(x_coords))]

    # Calculate velocities (simple difference between consecutive positions)
    x_velocities = [x_coords[i+1] - x_coords[i] for i in range(len(x_coords) - 1)]
    y_velocities = [y_coords[i+1] - y_coords[i] for i in range(len(y_coords) - 1)]
    time_velocities = time[1:] # Velocities are calculated for one frame less

    # Plotting
    plt.figure(figsize=(12, 8))

    plt.subplot(2, 2, 1)
    plt.plot(time, x_coords, marker='o', linestyle='-')
    plt.xlabel("Time (s)")
    plt.ylabel("X Position (pixels)")
    plt.title("X Position vs. Time")
    plt.grid(True)

    plt.subplot(2, 2, 2)
    plt.plot(time, y_coords, marker='o', linestyle='-')
    plt.xlabel("Time (s)")
    plt.ylabel("Y Position (pixels)")
    plt.title("Y Position vs. Time")
    plt.grid(True)

    plt.subplot(2, 2, 3)
    plt.plot(time_velocities, x_velocities, marker='o', linestyle='-')
    plt.xlabel("Time (s)")
    plt.ylabel("X Velocity (pixels/frame)")
    plt.title("X Velocity vs. Time")
    plt.grid(True)

    plt.subplot(2, 2, 4)
    plt.plot(time_velocities, y_velocities, marker='o', linestyle='-')
    plt.xlabel("Time (s)")
    plt.ylabel("Y Velocity (pixels/frame)")
    plt.title("Y Velocity vs. Time")
    plt.grid(True)

    plt.tight_layout()  # Adjusts subplot parameters for a tight layout
    plt.show()



from google.colab.patches import cv2_imshow

import cv2
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

# Load the image
#img = cv2.imread('/content/drive/MyDrive/BNP/img1.jpg', 0)  # Read as grayscale
#img = cv2.imread('/content/drive/MyDrive/BNP/img2.jpg', 0)
#img = cv2.imread('/content/drive/MyDrive/BNP/img3.png', 0)
img = cv2.imread('/content/drive/MyDrive/BNP/WhatsApp Image 2024-11-20 at 10.38.52 PM (1).jpeg', 0)
#img = cv2.imread('/content/drive/MyDrive/BNP/WhatsApp Image 2024-11-20 at 10.38.52 PM.jpeg', 0)
#img = cv2.imread('/content/drive/MyDrive/BNP/img with noise.jpeg', 0)

cv2_imshow(img)
# cv2.waitKey(0)
# cv2.destroyAllWindows()

img = cv2.imread('/content/drive/MyDrive/BNP/img with noise.jpeg') # Load as color

# Convert the image to HSV format
hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

# Display the HSV image
cv2_imshow(hsv_img)

blur = cv2.GaussianBlur(img, (5, 5), 0)

# Apply Hough Circle transform to detect circles
circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=30, minRadius=10, maxRadius=100)

if circles is not None:
    # Convert the (x, y) coordinates and radius of the circles to integers
    circles = np.round(circles[0, :]).astype("int")

    # Loop over the (x, y) coordinates and radius of the circles
    for (x, y, r) in circles:
        # Draw the circle in the output image
        cv2.circle(img, (x, y), r, (0, 255, 0), 2)

        # Calculate the center and width of the ball
        center = (x, y)
        width = 2 * r

        # Print the position, center, and width of the ball
        print(f"Position: ({x}, {y})")
        print(f"Center: {center}")
        print(f"Width: {width}")

    # Display the output image
    cv2_imshow(img)
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()

else:
    print("No circles detected in the image.")



import matplotlib.pyplot as plt
from scipy.ndimage import binary_fill_holes # Import binary_fill_holes from scipy.ndimage
from skimage.morphology import remove_small_objects

#img = cv2.imread('/content/drive/MyDrive/BNP/WhatsApp Image 2024-11-20 at 10.38.52 PM (1).jpeg')
img = cv2.imread('/content/drive/MyDrive/BNP/img with noise.jpeg')
#img = cv2.imread('/content/drive/MyDrive/BNP/img2.jpg')
#img = cv2.imread('/content/drive/MyDrive/BNP/WhatsApp Image 2024-11-20 at 10.38.52 PM.jpeg')

# Convert to RGB for processing
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Extract the red channel
red_channel = img[:, :, 2]

# Convert the original image to grayscale
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Display the original image
plt.imshow(img_rgb)
plt.title("Original Image")
plt.axis('off')
plt.show()

# Subtract grayscale from red channel
subtraction_result = cv2.subtract(red_channel, gray_img)

# Display the subtraction result
plt.imshow(subtraction_result, cmap='gray')
plt.title("Subtraction Result")
plt.axis('off')
plt.show()

# Normalize the subtraction result for thresholding
normalized = subtraction_result / 255.0

# Apply binary threshold with a value of 0.05
_, binary_img = cv2.threshold((normalized * 255).astype(np.uint8), int(0.05 * 255), 255, cv2.THRESH_BINARY)

# Display the binary image
plt.imshow(binary_img, cmap='gray')
plt.title("Binary Image")
plt.axis('off')
plt.show()

# Normalize the subtraction result for thresholding
normalized = subtraction_result / 255.0

# Apply binary threshold with a value of 0.05
_, binary_img = cv2.threshold((normalized * 255).astype(np.uint8), int(0.08 * 255), 255, cv2.THRESH_BINARY)

# Display the binary image
plt.imshow(binary_img, cmap='gray')
plt.title("Binary Image")
plt.axis('off')
plt.show()

# Fill small holes using skimage's binary_fill_holes
filled_img = binary_fill_holes(binary_img).astype(np.uint8) * 255

# Display the filled image
plt.imshow(filled_img, cmap='gray')
plt.title("Image After Filling Small Holes")
plt.axis('off')
plt.show()

# Convert the filled image to boolean for skimage processing
binary_bool = filled_img.astype(bool)

# Remove small objects with less than 500 pixels
processed_img = remove_small_objects(binary_bool, min_size=7460).astype(np.uint8) * 255

# Display the result
plt.imshow(processed_img, cmap='gray')
plt.title("Removed Small Objects")
plt.axis('off')
plt.show()

# Label connected components
num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(processed_img, connectivity=8)

# Overlay centroid on original image
for centroid in centroids[1:]:  # Skip background
    x, y = int(centroid[0]), int(centroid[1])
    cv2.circle(img_rgb, (x, y), 5, (255, 0, 0), -1)  # Red circle

# Display the labeled image
plt.imshow(img_rgb)
plt.title("Centroid Overlay")
plt.axis('off')
plt.show()

# Iterate through detected components (skip the first label which is the background)
for label in range(1, num_labels):
    # Extract component stats
    x, y, w, h, area = stats[label]

    # Skip components with area < 500 (already filtered, but double-checking)
    if area < 500:
        continue

    # Draw a bounding box (square) around the ball
    cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green rectangle

    # Annotate the centroid position on the image
    centroid_x, centroid_y = int(centroids[label][0]), int(centroids[label][1])
    cv2.putText(img_rgb, f"({centroid_x}, {centroid_y})",
                (centroid_x - 20, centroid_y - 20),
                cv2.FONT_HERSHEY_SIMPLEX,
                1.5,
                (0, 255, 0), 2)  # Green text

# Display the annotated image with bounding box and position
plt.imshow(img_rgb)
plt.title("Detected Ball with Bounding Box and Position")
plt.axis('off')
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.morphology import remove_small_objects, closing, disk


# Apply morphological closing to remove noise
cleaned_img = closing(binary_img, disk(3))  # Closing operation to fill small holes

# Remove small objects less than 500 pixels in area
cleaned_img = remove_small_objects(cleaned_img, min_size=500)

# Convert the cleaned binary image back to uint8 for further processing
cleaned_img = (cleaned_img * 255).astype(np.uint8)

# Find connected components in the cleaned image
num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(cleaned_img)

# Initialize variables to track the largest component (the ball)
largest_area = 0
largest_label = 0

# Loop through all components to find the largest one
for label in range(1, num_labels):  # Skip background label (0)
    x, y, w, h, area = stats[label]
    if area > largest_area:
        largest_area = area
        largest_label = label

# If the largest object is found, draw a bounding box and annotate the centroid
if largest_label > 0:
    # Get the bounding box and centroid of the largest component
    x, y, w, h, area = stats[largest_label]
    centroid_x, centroid_y = int(centroids[largest_label][0]), int(centroids[largest_label][1])

    # Draw a thick bounding box (square) around the largest object (ball)
    cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (255, 0, 0), 6)  # Blue rectangle with thickness 6

    # Annotate the centroid position with larger text
    cv2.putText(img_rgb, f"({centroid_x}, {centroid_y})",
                (centroid_x - 50, centroid_y - 20),
                cv2.FONT_HERSHEY_SIMPLEX,
                2,  # Larger font size
                (255, 0, 0), 4)  # Blue text with thickness 4

# Display the final image with the bounding box and centroid annotation
plt.imshow(img_rgb)
plt.title("Detected Ball with Bounding Box and Position")
plt.axis('off')
plt.show()



# Plot the position measurement of the image, from (0,0) to rest
plt.plot([0, img.shape[1]], [0, img.shape[0]], 'r-', label='Measurement')

# Show the mesh
plt.imshow(img, cmap='gray')

# Set the title and axes labels
plt.title('Position Measurement')
plt.xlabel('X')
plt.ylabel('Y')

# Show the plot
plt.show()

#img = cv2.imread('/content/drive/MyDrive/BNP/img1.jpg')
img = cv2.imread('/content/drive/MyDrive/BNP/WhatsApp Image 2024-11-20 at 10.38.52 PM (1).jpeg')
#img = cv2.imread('/content/drive/MyDrive/BNP/img3.png')



# Create a copy of the original image for drawing
output = img.copy()

# Convert the image to grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Apply Gaussian blur to reduce noise
blur = cv2.GaussianBlur(gray, (5, 5), 0)

# Apply Hough Circle transform to detect circles
circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=30, minRadius=10, maxRadius=100)

if circles is not None:
    # Convert the (x, y) coordinates and radius of the circles to integers
    circles = np.round(circles[0, :]).astype("int")

    # Loop over the (x, y) coordinates and radius of the circles
    for (x, y, r) in circles:
        # Draw the circle in the output image
        cv2.circle(output, (x, y), r, (0, 255, 0), 2)

        # Simulate ball movement
        x += 10  # Adjust the x-coordinate for horizontal movement
        y += 5   # Adjust the y-coordinate for vertical movement

        # Draw the moved circle in the output image
        cv2.circle(output, (x, y), r, (0, 255, 0), 2)

# Display the output image
cv2_imshow(output)
# cv2.waitKey(0)
# cv2.destroyAllWindows()

output = img.copy()
# Apply Gaussian blur to reduce noise
blur = cv2.GaussianBlur(gray, (5, 5), 0)

# Apply Hough Circle transform to detect circles
circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=30, minRadius=10, maxRadius=100)

if circles is not None:
    # Convert the (x, y) coordinates and radius of the circles to integers
    circles = np.round(circles[0, :]).astype("int")

    # Loop over the (x, y) coordinates and radius of the circles
    for (x, y, r) in circles:
        # Initialize the ball path
        ball_path = []

        # Draw the circle in the output image
        cv2.circle(output, (x, y), r, (0, 255, 0), 2)
        ball_path.append((x, y))  # Add the initial ball position to the path

        # Simulate ball movement and plot the path
        for _ in range(10):  # Adjust the number of points to plot
            x += np.random.randint(-20, 21)  # Adjust the x-coordinate randomly
            y += np.random.randint(-20, 21)  # Adjust the y-coordinate randomly

            # Draw the moved circle in the output image
            cv2.circle(output, (x, y), r, (0, 255, 0), 2)
            ball_path.append((x, y))  # Add the new ball position to the path

        # Plot the ball path
        for i in range(len(ball_path) - 1):
            cv2.line(output, ball_path[i], ball_path[i + 1], (0, 0, 255), 2)

# Display the output image
cv2_imshow(output)
# cv2.waitKey(0)
# cv2.destroyAllWindows()

output = img.copy()
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Apply Gaussian blur to reduce noise
blur = cv2.GaussianBlur(gray, (5, 5), 0)

# Apply Hough Circle transform to detect circles
circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=30, minRadius=10, maxRadius=100)

if circles is not None:
    # Convert the (x, y) coordinates and radius of the circles to integers
    circles = np.round(circles[0, :]).astype("int")

    # Loop over the (x, y) coordinates and radius of the circles
    for (x, y, r) in circles:
        # Initialize the ball path
        ball_path = []

        # Draw the circle in the output image
        cv2.circle(output, (x, y), r, (0, 255, 0), 2)
        ball_path.append((x, y))  # Add the initial ball position to the path

        # Simulate ball movement and plot the path
        for _ in range(20):  # Adjust the number of points to plot
            x += np.random.randint(-100, 101)  # Adjust the x-coordinate randomly within a wider range
            y += np.random.randint(-100, 101)  # Adjust the y-coordinate randomly within a wider range

            # Ensure the ball stays within the image boundaries
            x = max(r, min(x, img.shape[1] - r))
            y = max(r, min(y, img.shape[0] - r))

            # Draw the moved circle in the output image
            cv2.circle(output, (x, y), r, (0, 255, 0), 2)
            ball_path.append((x, y))  # Add the new ball position to the path

        # Plot the ball path
        for i in range(len(ball_path) - 1):
            cv2.line(output, ball_path[i], ball_path[i + 1], (0, 0, 255), 2)

# Display the output image
cv2_imshow(output)
# cv2.waitKey(0)
# cv2.destroyAllWindows()

output = img.copy()

# Convert the image to grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Apply Gaussian blur to reduce noise
blur = cv2.GaussianBlur(gray, (5, 5), 0)

# Apply Hough Circle transform to detect circles
circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=30, minRadius=10, maxRadius=100)

if circles is not None:
    # Convert the (x, y) coordinates and radius of the circles to integers
    circles = np.round(circles[0, :]).astype("int")

    # Loop over the (x, y) coordinates and radius of the circles
    for (x, y, r) in circles:
        # Initialize the ball path
        ball_path = []

        # Draw the circle in the output image
        cv2.circle(output, (x, y), r, (0, 255, 0), 2)
        ball_path.append((x, y, 0))  # Add the initial ball position to the path with z=0

        # Simulate ball movement and plot the path
        for _ in range(20):  # Adjust the number of points to plot
            x += np.random.randint(-100, 101)  # Adjust the x-coordinate randomly within a wider range
            y += np.random.randint(-100, 101)  # Adjust the y-coordinate randomly within a wider range
            z = np.random.randint(0, 101)  # Add a random z-coordinate to simulate 3D movement

            # Ensure the ball stays within the image boundaries
            x = max(r, min(x, img.shape[1] - r))
            y = max(r, min(y, img.shape[0] - r))

            # Draw the moved circle in the output image
            cv2.circle(output, (x, y), r, (0, 255, 0), 2)
            ball_path.append((x, y, z))  # Add the new ball position to the path with z-coordinate

        # Plot the 3D ball path
        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        x_coords, y_coords, z_coords = zip(*ball_path)
        ax.plot(x_coords, y_coords, z_coords)
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')
        ax.set_title('Ball Path')
        plt.show()

# Display the output image
cv2_imshow(output)
# cv2.waitKey(0)
# cv2.destroyAllWindows()

output = img.copy()

# Convert the image to grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Apply Gaussian blur to reduce noise
blur = cv2.GaussianBlur(gray, (5, 5), 0)

# Apply Hough Circle transform to detect circles
circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, 100, param1=100, param2=30, minRadius=10, maxRadius=100)

if circles is not None:
    # Convert the (x, y) coordinates and radius of the circles to integers
    circles = np.round(circles[0, :]).astype("int")

    # Loop over the (x, y) coordinates and radius of the circles
    for (x, y, r) in circles:
        # Initialize the ball position and path
        ball_pos = (x, y)
        ball_path = [(x, y)]

        # Define the center of the plate
        plate_center = (img.shape[1] // 2, img.shape[0] // 2)

        # Define the control parameters
        kp = 0.1  # Proportional gain
        ki = 0.01  # Integral gain
        integral = 0

        # Simulate ball balancing
        for _ in range(100):
            # Calculate the error between ball position and plate center
            error = np.array(plate_center) - np.array(ball_pos)

            # Apply the control law
            integral += error
            tilt = kp * error + ki * integral

            # Update the ball position based on the tilt
            ball_pos = (int(ball_pos[0] + tilt[0]), int(ball_pos[1] + tilt[1]))

            # Ensure the ball stays within the image boundaries
            ball_pos = (max(r, min(ball_pos[0], img.shape[1] - r)), max(r, min(ball_pos[1], img.shape[0] - r)))

            # Draw the ball on the output image
            cv2.circle(output, ball_pos, r, (0, 255, 0), 2)

            # Add the new ball position to the path
            ball_path.append(ball_pos)

        # Plot the ball path and coordinates
        plt.figure(figsize=(8, 6))
        plt.subplot(1, 2, 1)
        plt.imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))
        plt.title('Balanced Ball')
        plt.axis('off')

        plt.subplot(1, 2, 2)
        x_coords, y_coords = zip(*ball_path)
        plt.plot(x_coords, y_coords)
        plt.scatter(x_coords, y_coords, s=10, c='r')
        plt.title('Ball Path and Coordinates')
        plt.xlabel('X')
        plt.ylabel('Y')

        plt.tight_layout()
        plt.show()

# Display the output image
cv2_imshow(output)
# cv2.waitKey(0)
# cv2.destroyAllWindows()





# Path to your video file
video_path = '/content/drive/MyDrive/BNP/Take-1.mp4'

# Initialize video capture object
cap = cv2.VideoCapture(video_path)

# Initialize Lucas-Kanade optical flow parameters
lk_params = dict(winSize=(15, 15),
                 maxLevel=2,
                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

# Initialize color for visualizing tracked points
color = (0, 255, 0)

# Read the first frame
ret, old_frame = cap.read()
old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)

# Select some random points to track
p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)

# Create a mask image for drawing purposes
mask = np.zeros_like(old_frame)

while True:
    # Read the current frame and convert to grayscale
    ret, frame = cap.read()
    if not ret:
        break
    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Calculate optical flow using Lucas-Kanade method
    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

    # Select good points
    good_new = p1[st == 1]
    good_old = p0[st == 1]

    # Draw tracks
    for i, (new, old) in enumerate(zip(good_new, good_old)):
        a, b = new.ravel()
        c, d = old.ravel()
        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color, 2)
        frame = cv2.circle(frame, (int(a), int(b)), 5, color, -1)

    # Overlay tracks on the original frame
    img = cv2.add(frame, mask)

    # Display the frame
    cv2_imshow(img)

    # Exit if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

    # Update previous frame and points
    old_gray = frame_gray.copy()
    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, maxCorners=100, qualityLevel=0.3, minDistance=10, blockSize=7)

# Release video capture and close all windows
cap.release()
cv2.destroyAllWindows()

import cv2
import numpy as np

# Path to your video file
video_path = '/content/drive/MyDrive/BNP/VID-1713506997713.mp4'

# Initialize video capture object
cap = cv2.VideoCapture(video_path)

# Get the video frame width and height
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# Define the codec and create VideoWriter object
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('output2_video_opticalflow.mp4', fourcc, 30.0, (frame_width, frame_height))

# Initialize Lucas-Kanade optical flow parameters
lk_params = dict(winSize=(15, 15),
                 maxLevel=2,
                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

# Initialize color for visualizing tracked points
color = (0, 255, 0)

# Read the first frame
ret, old_frame = cap.read()
old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)

# Select some random points to track
p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)

# Create a mask image for drawing purposes
mask = np.zeros_like(old_frame)

while True:
    # Read the current frame and convert to grayscale
    ret, frame = cap.read()
    if not ret:
        break
    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Calculate optical flow using Lucas-Kanade method
    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

    # Select good points
    good_new = p1[st == 1]
    good_old = p0[st == 1]

    # Draw tracks
    for i, (new, old) in enumerate(zip(good_new, good_old)):
        a, b = new.ravel()
        c, d = old.ravel()
        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color, 2)
        frame = cv2.circle(frame, (int(a), int(b)), 5, color, -1)

    # Overlay tracks on the original frame
    img = cv2.add(frame, mask)

    # Write the frame to the output video file
    out.write(img)

    # Display the frame
    cv2_imshow(img)

    # Exit if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

    # Update previous frame and points
    old_gray = frame_gray.copy()
    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, maxCorners=100, qualityLevel=0.3, minDistance=10, blockSize=7)

# Release video capture and writer objects
cap.release()
out.release()
cv2.destroyAllWindows()



from scipy.integrate import odeint

# System parameters
mb = 0.1  # Mass of the ball (kg)
rb = 0.02  # Radius of the ball (m)
Ib = (2/5) * mb * rb**2  # Moment of inertia of the ball (kg.m^2)
g = 9.81  # Acceleration due to gravity (m/s^2)

def ball_plate_model(X, t, alpha, beta):
    x, xdot, y, ydot = X

    # Evaluate the plate inclination angles at the current time
    alpha_t = alpha(t)
    beta_t = beta(t)

    # Equations of motion
    xddot = (mb * g * np.sin(alpha_t) - mb * (xdot * alpha_dot(t) + y * alpha_dot(t) * beta_dot(t))) / (mb + (Ib / rb**2))
    yddot = (mb * g * np.sin(beta_t) - mb * (ydot * beta_dot(t) + x * alpha_dot(t) * beta_dot(t))) / (mb + (Ib / rb**2))

    return [xdot, xddot, ydot, yddot]

# Initial conditions
x0 = 0.0  # Initial x position (m)
y0 = 0.0  # Initial y position (m)
xdot0 = 0.0  # Initial x velocity (m/s)
ydot0 = 0.0  # Initial y velocity (m/s)
X0 = [x0, xdot0, y0, ydot0]  # Initial state vector

# Time span
t_start = 0.0  # Start time (s)
t_end = 10.0  # End time (s)
t_span = np.linspace(t_start, t_end, 1000)  # Time vector

# Time derivatives of plate inclination angles
alpha_dot = lambda t: np.pi/4 * np.cos(t)
beta_dot = lambda t: -np.pi/6 * np.sin(t)

# Solve the equations of motion

sol = odeint(ball_plate_model, X0, t_span, args=(alpha_dot, beta_dot))

# Extract the state variables
x = sol[:, 0]
xdot = sol[:, 1]
y = sol[:, 2]
ydot = sol[:, 3]

# Plot the results
plt.figure(figsize=(12, 8))
plt.subplot(2, 2, 1)
plt.plot(t_span, x)
plt.title('X Position')
plt.xlabel('Time (s)')
plt.ylabel('Position (m)')

plt.subplot(2, 2, 2)
plt.plot(t_span, xdot)
plt.title('X Velocity')
plt.xlabel('Time (s)')
plt.ylabel('Velocity (m/s)')

plt.subplot(2, 2, 3)
plt.plot(t_span, y)
plt.title('Y Position')
plt.xlabel('Time (s)')
plt.ylabel('Position (m)')

plt.subplot(2, 2, 4)
plt.plot(t_span, ydot)
plt.title('Y Velocity')
plt.xlabel('Time (s)')
plt.ylabel('Velocity (m/s)')

plt.tight_layout()
plt.show()

import numpy as np
from scipy.integrate import odeint

# System parameters
mb = 0.1
rb = 0.02
Ib = (2/5) * mb * rb**2
g = 9.81

# PID controller gains
Kp_x = -0.3  # Proportional gain for x-axis
Kd_x = -0.337  # Derivative gain for x-axis
Kp_y = -0.3  # Proportional gain for y-axis
Kd_y = -0.337  # Derivative gain for y-axis

# Desired setpoint
x_desired = 0.1  # Desired x position (m)
y_desired = 0.1  # Desired y position (m)

def ball_plate_model(X, t):
    x, xdot, y, ydot = X

    # PID control law
    error_x = x - x_desired
    error_y = y - y_desired
    u_x = Kp_x * error_x + Kd_x * xdot
    u_y = Kp_y * error_y + Kd_y * ydot

    # Equations of motion
    xddot = (mb * g * u_x - mb * (xdot * u_y + y * u_x * u_y)) / (mb + (Ib / rb**2))
    yddot = (mb * g * u_y - mb * (ydot * u_y + x * u_x * u_y)) / (mb + (Ib / rb**2))

    return [xdot, xddot, ydot, yddot]

# Initial conditions
x0 = 0.0
y0 = 0.0
xdot0 = 0.0
ydot0 = 0.0
X0 = [x0, xdot0, y0, ydot0]

# Time span
t_start = 0.0
t_end = 10.0
t_span = np.linspace(t_start, t_end, 1000)

# Solve the equations of motion
sol = odeint(ball_plate_model, X0, t_span)

# Extract the state variables
x = sol[:, 0]
xdot = sol[:, 1]
y = sol[:, 2]
ydot = sol[:, 3]

# Plot the results
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))
plt.subplot(2, 2, 1)
plt.plot(t_span, x)
plt.axhline(y=x_desired, color='r', linestyle='--')
plt.title('X Position')
plt.xlabel('Time (s)')
plt.ylabel('Position (m)')

plt.subplot(2, 2, 2)
plt.plot(t_span, xdot)
plt.title('X Velocity')
plt.xlabel('Time (s)')
plt.ylabel('Velocity (m/s)')

plt.subplot(2, 2, 3)
plt.plot(t_span, y)
plt.axhline(y=y_desired, color='r', linestyle='--')
plt.title('Y Position')
plt.xlabel('Time (s)')
plt.ylabel('Position (m)')

plt.subplot(2, 2, 4)
plt.plot(t_span, ydot)
plt.title('Y Velocity')
plt.xlabel('Time (s)')
plt.ylabel('Velocity (m/s)')

plt.tight_layout()
plt.show()

# libraries
import math
import time

# objects
# Assume Pixy2SPI_SS and MicroMaestro are defined elsewhere

# CONSTANTS
# Constants defining servo positions and offsets
ABS_0 = 4000  # ms position of absolute 0 degrees
ABS_90 = 8000  # ms position of absolute 90 degrees
TO_DEG = 180 / math.pi  # radians to degrees conversion factor
X, Y, Z = 0, 1, 2  # defines x, y, and z array indexes to be used
ID = ["a1", "a2", "b1", "b2", "c1", "c2"]  # servo IDs

# USER DEFINED VALUES
# Angle range and offset for each servo
RANGE = [[-45, 45], [45, -45], [-45, 45], [45, -45], [-45, 45], [45, -45]]
OFFSET = [0, 0, 0, 0, 0, 0]

# INVERSE KINEMATICS CONSTANTS
# User-defined lengths (in mm)
L0 = 73.025
LF = 67.775
D1 = 36.8893
D2 = 38.1
M = 12.7
P1 = 31.75
P2 = 129

# Intermediate variables for inverse kinematics calculations
T = (pow(LF, 2) * math.sqrt(3)) / 2
U = math.sqrt(pow(L0, 2) + pow(D1, 2)) * math.sin((2 * math.pi / 3) - math.atan(L0 / D1))
NAB = [math.sqrt(3) * 0.5, -0.5, 0]
NAC = [math.sqrt(3) * 0.5, 0.5, 0]
NBC = [0, 1, 0]

# Define initial values for ball and PID control
ORIGIN = [0, 0]  # X and Y co-ords of the origin
R_PLATFORM = 0  # the distance from the center of the platform to the corner of the platform seen from the pixy2 cam
BALL = [0, 0]  # X and Y co-ords of the ball
ERROR = [0, 0]  # error of the ball
ERROR_PREV = [0, 0]  # previous error value used to calculate derivative
DERIV = [0, 0]  # derivative of the error
DERIV_PREV = [0, 0]  # previous derivative value
KP = 6e-4  # proportional constant
KD = 0.56  # derivative constant
OUT = [0, 0]  # output values (nx and ny)
TIME_I = 0  # initial time
TIME_F = 0  # final time

# FUNCTIONS
def move_servo(i, pos, spd, acc):
    pos += OFFSET[i]  # adds offset amount to the input position
    pos = map(pos, RANGE[i][0], RANGE[i][1], ABS_0, ABS_90)  # converts input pos to ms position
    # code to move servo i to position 'pos' at speed 'spd' and acceleration 'acc'

def move_servos(theta, spd, acc): # Pass theta to this function
    for i in range(6):
        pos = theta[i] + OFFSET[i]  # adds offset amount to the calculated angle
        pos = map(pos, RANGE[i][0], RANGE[i][1], ABS_0, ABS_90)  # converts input pos to ms position
        # code to move servo i to position 'pos' at speed 'spd' and acceleration 'acc'

def find_ball():
    global BALL
    # code to find the location of the ball using the pixy2 cam
    # assign the detected ball's X and Y co-

def pd():
    global ERROR, ERROR_PREV, DERIV, DERIV_PREV, OUT, TIME_I, TIME_F
    find_ball()  # finds the location of the ball
    if BALL[X] == 4004 and BALL[Y] == 4004:
        # sees if ball position (x and y) is 4004, if so then the ball is not detected and platform should be in home position
        inverse_kinematics(0, 0, HZ_NORM, 0, 0, 0)  # hx, hy, hz, nx, ny, ax
        move_servos(20, 20, 20) # Added acceleration argument
    else:
        # calculates the proportional and derivative terms and outputs them to the platform
        # calculate error
        ERROR[X] = ORIGIN[X] - BALL[X]  # x component of error
        ERROR[Y] = BALL[Y] - ORIGIN[Y]  # y component of error
        TIME_F = time()  # gets final time
        #dt = TIME_F - TIME_I
        dt = 0.1  # time difference
        HZ_NORM = 1
        # calculates the derivative of the error
        DERIV[X] = (ERROR[X] - ERROR_PREV[X]) / dt  # x component of derivative of the error
        DERIV[Y] = (ERROR[Y] - ERROR_PREV[Y]) / dt  # y component of derivative of the error
        # calculates the output based on the error and derivative
        OUT[X] = KP * ERROR[X] + KD * DERIV[X]  # x component of output
        OUT[Y] = KP * ERROR[Y] + KD * DERIV[Y]  # y component of output
        inverse_kinematics(0, 0, HZ_NORM, OUT[X], OUT[Y], 0)  # hx, hy, hz, nx, ny, ax
        move_servos(20, 20, 20) # Added acceleration argument
        # update values for next iteration
        TIME_I = TIME_F
        ERROR_PREV = ERROR
        DERIV_PREV = DERIV

def inverse_kinematics(hx, hy, hz, nx, ny, ax):
    # inverse kinematics calculations
    T1 = (hx + M * nx) / P1
    T2 = (hy + M * ny) / P1
    T3 = (hz + M * ax) / P2
    alpha = (T1 + T2) / 2
    beta = (T1 - T2) / 2
    gamma = T3
    alpha_b = math.atan2(beta, alpha)
    gamma_b = math.atan2(gamma, math.sqrt(alpha ** 2 + beta ** 2))
    T = math.sqrt(alpha ** 2 + beta ** 2 + gamma ** 2)
    theta = [0] * 6
    theta[0] = alpha_b
    theta[1] = alpha_b + 2 * math.pi / 3
    theta[2] = alpha_b - 2 * math.pi / 3
    theta[3] = gamma_b
    theta[4] = gamma_b + 2 * math.pi / 3
    theta[5] = gamma_b - 2 * math.pi / 3
    for i in range(6):
        theta[i] *= TO_DEG  # convert angles to degrees
    return theta

def map(x, in_min, in_max, out_min, out_max):
    # maps an input range to an output range
    return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min

def time():
    # returns current time
    # you would implement this function according to your platform's timekeeping mechanism
    pass

# Main Loop
TIME_I = time()  # initializes initial time
while True:
    pd()  # performs proportional-derivative control

# inverse kinematics
    hx = read_encoder(encoder_hx)
    hy = read_encoder(encoder_hy)
    hz = read_encoder(encoder_hz)
    nx = read_encoder(encoder_nx)
    ny = read_encoder(encoder_ny)
    ax = read_encoder(encoder_ax)
    theta = inverse_kinematics(hx, hy, hz, nx, ny, ax)

    # map joint angles to servo positions
    servo_positions = [0] * 6
    for i in range(6):
        servo_positions[i] = map(theta[i], -90, 90, 0, 180)

    # update servo positions
    for i in range(6):
        set_servo_position(servo_pins[i], servo_positions[i])

    # control loop timing
    TIME_F = time()  # final time
    elapsed_time = TIME_F - TIME_I
    if elapsed_time < T:
        sleep(T - elapsed_time)  # wait to maintain loop rate
    TIME_I = time()  # update initial time

from mpl_toolkits.mplot3d import Axes3D

# System parameters
m_ball = 0.1  # Mass of the ball (kg)
r_ball = 0.02  # Radius of the ball (m)
g = 9.81  # Acceleration due to gravity (m/s^2)

# Initial conditions
x0 = 0.1  # Initial x position of the ball (m)
y0 = 0.1  # Initial y position of the ball (m)
vx0 = 0.0  # Initial x velocity of the ball (m/s)
vy0 = 0.0  # Initial y velocity of the ball (m/s)
alpha0 = 0.0  # Initial plate tilt angle in x direction (rad)
beta0 = 0.0  # Initial plate tilt angle in y direction (rad)

# Simulation parameters
t_end = 10.0  # Simulation end time (s)
dt = 0.01  # Time step (s)

# Desired ball position
x_des = 0.0
y_des = 0.0

# Controller gains
Kp_x = 10.0  # Proportional gain for x
Kp_y = 10.0  # Proportional gain for y

# Linearized equations of motion (from Equations 2 and 3 in the paper)
def dxdt(x, y, vx, vy, alpha, beta):
    return vx

def dvxdt(x, y, vx, vy, alpha, beta):
    return (5 / 7) * g * alpha

def dydt(x, y, vx, vy, alpha, beta):
    return vy

def dvydt(x, y, vx, vy, alpha, beta):
    return (5 / 7) * g * beta

# Proportional controller
def control_alpha(x, x_des):
    return Kp_x * (x_des - x)

def control_beta(y, y_des):
    return Kp_y * (y_des - y)

# Simulation
t = 0.0
x = x0
y = y0
vx = vx0
vy = vy0
alpha = alpha0
beta = beta0

x_trace = [x]
y_trace = [y]
vx_trace = [vx]
vy_trace = [vy]
alpha_trace = [alpha]
beta_trace = [beta]

while t < t_end:
    # Calculate control inputs (plate tilt angles)
    alpha = control_alpha(x, x_des)
    beta = control_beta(y, y_des)

    x_dot = dxdt(x, y, vx, vy, alpha, beta)
    vx_dot = dvxdt(x, y, vx, vy, alpha, beta)
    y_dot = dydt(x, y, vx, vy, alpha, beta)
    vy_dot = dvydt(x, y, vx, vy, alpha, beta)

    x += x_dot * dt
    vx += vx_dot * dt
    y += y_dot * dt
    vy += vy_dot * dt

    x_trace.append(x)
    y_trace.append(y)
    vx_trace.append(vx)
    vy_trace.append(vy)
    alpha_trace.append(alpha)
    beta_trace.append(beta)

    t += dt

# 3D Plotting
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

ax.plot(x_trace, y_trace, zs=0, zdir='z', label='Ball Trajectory')
ax.scatter(x_des, y_des, 0, c='r', marker='*', s=100, label='Desired Position')

ax.set_xlabel('X (m)')
ax.set_ylabel('Y (m)')
ax.set_zlabel('Z (m)')
ax.set_title('Ball Trajectory on the Plate')
ax.legend()

plt.show()

